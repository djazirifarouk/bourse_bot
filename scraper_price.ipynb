{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6e7688c",
   "metadata": {},
   "source": [
    "Loading Quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d5661a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 86 quotes from the latest published date: 2026-02-07\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load only the Company_Name and Quote_Code of the latest Publication_Date\n",
    "quotes_df = pd.read_csv('quotes_potential.csv', usecols=['Company_Name', 'Quote_Code', 'Publication_Date'])\n",
    "quotes_df['Publication_Date'] = pd.to_datetime(quotes_df['Publication_Date'])\n",
    "latest_date = quotes_df['Publication_Date'].max()\n",
    "latest_quotes_df = quotes_df[quotes_df['Publication_Date'] == latest_date][['Quote_Code', 'Company_Name']]\n",
    "print(f\"✅ Loaded {len(latest_quotes_df)} quotes from the latest published date: {latest_date.strftime('%Y-%m-%d')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80db98b8",
   "metadata": {},
   "source": [
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7c5f3f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created mapping for 94 symbols\n",
      "Sample mappings: {'AETEC': 'AETECH', 'AL': 'AIR LIQUIDE TSIE', 'ALKIM': 'ALKIMIA', 'AB': 'AMEN BANK', 'AMS': 'AMS'}\n",
      "⚠️  6 symbols had no mapping and were set to NaN\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "headers = {\n",
    "    'Accept': '*/*',\n",
    "    'Accept-Language': 'en-US,en;q=0.5',\n",
    "    'Connection': 'keep-alive',\n",
    "    'Origin': 'https://irbe7.com',\n",
    "    'Referer': 'https://irbe7.com/',\n",
    "    'Sec-Fetch-Dest': 'empty',\n",
    "    'Sec-Fetch-Mode': 'cors',\n",
    "    'Sec-Fetch-Site': 'same-site',\n",
    "    'Sec-GPC': '1',\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/144.0.0.0 Safari/537.36',\n",
    "    'sec-ch-ua': '\"Not(A:Brand\";v=\"8\", \"Chromium\";v=\"144\", \"Brave\";v=\"144\"',\n",
    "    'sec-ch-ua-mobile': '?0',\n",
    "    'sec-ch-ua-platform': '\"Windows\"',\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'limit': '30',\n",
    "    'query': '',\n",
    "    'type': '',\n",
    "    'exchange': 'TN',\n",
    "}\n",
    "\n",
    "response = requests.get('https://data.irbe7.com/api/data/search', params=params, headers=headers)\n",
    "mapping_data = response.json()\n",
    "if isinstance(mapping_data, list):\n",
    "    symbol_to_ticker = {item['symbol']: item['ticker'] for item in mapping_data}\n",
    "else:\n",
    "    symbol_to_ticker = {mapping_data['symbol']: mapping_data['ticker']}\n",
    "\n",
    "print(f\"Created mapping for {len(symbol_to_ticker)} symbols\")\n",
    "print(\"Sample mappings:\", dict(list(symbol_to_ticker.items())[:5]))\n",
    "latest_quotes_df['Quote_Code_mapped'] = latest_quotes_df['Quote_Code'].map(symbol_to_ticker)\n",
    "# Handle any unmatched symbols (keep original if no mapping found)\n",
    "unmatched = latest_quotes_df['Quote_Code_mapped'].isna().sum()\n",
    "if unmatched > 0:\n",
    "    print(f\"⚠️  {unmatched} symbols had no mapping and were set to NaN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da0d778",
   "metadata": {},
   "source": [
    "prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "18be7e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "def get_timestamps(years=15):\n",
    "    \"\"\"Get 'from' and 'to' timestamps for the last N years\"\"\"\n",
    "    to_date = datetime.now()\n",
    "    from_date = to_date - timedelta(days=years * 365)\n",
    "    \n",
    "    # Convert to Unix timestamps (seconds)\n",
    "    to_timestamp = int(to_date.timestamp())\n",
    "    from_timestamp = int(from_date.timestamp())\n",
    "    \n",
    "    return from_timestamp, to_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc34e388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data from 2011-02-11 15:57:04 to 2026-02-07 15:57:04\n",
      "❌ No quote data found for nan\n",
      "✅ AETECH: 6799 rows, from 2013-04-08 to 2026-01-23\n",
      "✅ AIR LIQUIDE TSIE: 14249 rows, from 2010-04-27 to 2026-02-06\n",
      "✅ AMEN BANK: 28242 rows, from 2010-05-26 to 2026-02-06\n",
      "✅ AMS: 3211 rows, from 2012-03-02 to 2023-07-05\n",
      "✅ ATB: 25757 rows, from 2010-04-13 to 2026-02-06\n",
      "✅ ATL: 25201 rows, from 2010-01-28 to 2026-02-06\n",
      "✅ ARTES: 26727 rows, from 2010-01-27 to 2026-02-06\n",
      "✅ ASSAD: 21371 rows, from 2010-04-15 to 2026-02-06\n",
      "✅ ASSUR MAGHREBIA: 9818 rows, from 2020-12-31 to 2026-02-06\n",
      "✅ ASTREE: 4447 rows, from 2010-02-19 to 2026-01-26\n",
      "✅ ATTIJARI BANK: 28692 rows, from 2010-02-02 to 2026-02-06\n",
      "✅ ATTIJARI LEASING: 20026 rows, from 2010-05-04 to 2026-02-06\n",
      "✅ BT: 27886 rows, from 2010-02-02 to 2026-02-06\n",
      "✅ BNA: 28441 rows, from 2010-02-01 to 2026-02-06\n",
      "✅ BEST LEASE: 6143 rows, from 2013-10-24 to 2026-02-05\n",
      "✅ BH ASSURANCE: 3014 rows, from 2011-04-13 to 2026-01-28\n",
      "✅ BH BANK: 22539 rows, from 2010-02-01 to 2026-02-06\n",
      "✅ BH LEASING: 15965 rows, from 2011-05-16 to 2026-02-06\n",
      "✅ BIAT: 28776 rows, from 2010-02-01 to 2026-02-06\n",
      "✅ BTE (ADP): 15108 rows, from 2010-02-03 to 2026-02-05\n",
      "✅ CARTHAGE CEMENT: 28740 rows, from 2010-07-14 to 2026-02-06\n",
      "✅ CELLCOM: 16025 rows, from 2014-02-21 to 2026-02-06\n",
      "❌ No quote data found for nan\n",
      "✅ CIL: 18872 rows, from 2010-02-09 to 2026-02-06\n",
      "✅ CIMENTS DE BIZERTE: 13802 rows, from 2010-04-26 to 2026-02-06\n",
      "✅ CITY CARS: 26300 rows, from 2013-11-27 to 2026-02-06\n",
      "✅ DELICE HOLDING: 26609 rows, from 2014-10-17 to 2026-02-06\n",
      "✅ ELECTROSTAR: 6383 rows, from 2010-04-14 to 2024-07-22\n",
      "✅ ENNAKL AUTOMOBILES: 23334 rows, from 2010-07-19 to 2026-02-06\n",
      "✅ ESSOUKNA: 17290 rows, from 2010-04-27 to 2026-02-06\n",
      "✅ EURO-CYCLES: 27707 rows, from 2013-06-25 to 2026-02-06\n",
      "✅ GIF-FILTER: 7846 rows, from 2010-03-17 to 2024-10-22\n",
      "✅ HANNIBAL LEASE: 11039 rows, from 2013-07-08 to 2026-02-06\n",
      "❌ No quote data found for nan\n",
      "✅ ICF: 25022 rows, from 2010-05-17 to 2026-02-06\n",
      "✅ LAND OR: 24908 rows, from 2013-03-11 to 2026-02-06\n",
      "✅ MAGASIN GENERAL: 11670 rows, from 2010-04-27 to 2026-02-05\n",
      "✅ ASSU MAGHREBIA VIE: 21470 rows, from 2023-01-02 to 2026-02-06\n",
      "✅ ATELIER MEUBLE INT: 26598 rows, from 2017-06-05 to 2026-02-06\n",
      "✅ MAGHREB INTERN PUB: 1998 rows, from 2014-08-04 to 2024-07-29\n",
      "✅ MONOPRIX: 16156 rows, from 2010-05-10 to 2026-02-06\n",
      "✅ MPBS: 23936 rows, from 2014-01-15 to 2026-02-06\n",
      "✅ NEW BODY LINE: 20957 rows, from 2013-05-10 to 2026-02-06\n",
      "✅ OFFICEPLAST: 16625 rows, from 2015-10-16 to 2026-02-06\n",
      "✅ ONE TECH HOLDING: 27121 rows, from 2013-05-21 to 2026-02-06\n",
      "✅ POULINA GP HOLDING: 26922 rows, from 2010-04-19 to 2026-02-06\n",
      "✅ SAH: 27976 rows, from 2014-01-10 to 2026-02-06\n",
      "✅ SANIMED: 3910 rows, from 2017-03-02 to 2026-02-06\n",
      "✅ SERVICOM: 5675 rows, from 2010-05-11 to 2024-01-08\n",
      "✅ SFBT: 28842 rows, from 2010-04-26 to 2026-02-06\n",
      "✅ SIAME: 25625 rows, from 2010-04-26 to 2026-02-06\n",
      "✅ SIMPAR: 4287 rows, from 2010-04-26 to 2026-01-27\n",
      "✅ SIPHAT: 8040 rows, from 2010-04-26 to 2026-02-05\n",
      "✅ SITS: 7042 rows, from 2010-04-26 to 2026-02-03\n",
      "✅ SMART TUNISIE: 23378 rows, from 2021-12-31 to 2026-02-06\n",
      "✅ ALKIMIA: 5049 rows, from 2010-02-05 to 2026-02-03\n",
      "✅ SOMOCER: 24148 rows, from 2010-04-27 to 2026-02-06\n",
      "✅ SOPAT: 5974 rows, from 2010-04-27 to 2023-10-31\n",
      "✅ SOTEMAIL: 3013 rows, from 2014-01-30 to 2026-01-02\n",
      "✅ SOTETEL: 27620 rows, from 2010-04-27 to 2026-02-06\n",
      "✅ SOTIPAPIER: 25754 rows, from 2014-04-02 to 2026-02-06\n",
      "✅ SOTRAPIL: 24802 rows, from 2010-04-28 to 2026-02-06\n",
      "✅ SOTUMAG: 25079 rows, from 2010-04-05 to 2026-02-06\n",
      "✅ SOTUVER: 28419 rows, from 2010-01-04 to 2026-02-06\n",
      "✅ SPDIT - SICAF: 21993 rows, from 2010-04-27 to 2026-02-06\n",
      "✅ STA: 19837 rows, from 2022-03-18 to 2026-02-06\n",
      "✅ STAR: 15996 rows, from 2010-04-28 to 2026-02-06\n",
      "✅ STB: 27232 rows, from 2010-04-28 to 2026-02-06\n",
      "❌ No quote data found for nan\n",
      "✅ STIP: 9808 rows, from 2010-05-04 to 2026-01-30\n",
      "✅ TAWASOL GP HOLDING: 20228 rows, from 2014-07-17 to 2026-02-06\n",
      "✅ TELNET HOLDING: 27509 rows, from 2011-05-24 to 2026-02-06\n",
      "✅ TPR: 28146 rows, from 2010-05-03 to 2026-02-06\n",
      "✅ TUNINDEX: 31234 rows, from 2010-01-04 to 2026-02-06\n",
      "✅ TUNINVEST-SICAR: 7541 rows, from 2010-05-07 to 2026-02-06\n",
      "✅ TUNIS RE: 18568 rows, from 2011-01-07 to 2026-02-06\n",
      "✅ TUNISAIR: 20450 rows, from 2010-04-29 to 2026-02-06\n",
      "❌ No quote data found for nan\n",
      "✅ TUNISIE LEASING F: 22111 rows, from 2010-05-03 to 2026-02-06\n",
      "❌ No quote data found for nan\n",
      "✅ UADH: 13380 rows, from 2015-06-08 to 2026-02-06\n",
      "✅ UBCI: 8987 rows, from 2010-05-05 to 2026-02-06\n",
      "✅ UIB: 24892 rows, from 2010-05-05 to 2026-02-06\n",
      "✅ UNIMED: 26483 rows, from 2016-05-05 to 2026-02-06\n",
      "✅ WIFACK INT BANK: 16019 rows, from 2010-05-11 to 2026-02-06\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from_ts, to_ts = get_timestamps(years=15)\n",
    "print(f\"Fetching data from {datetime.fromtimestamp(from_ts)} to {datetime.fromtimestamp(to_ts)}\")\n",
    "\n",
    "prices = pd.DataFrame([])\n",
    "for quote in latest_quotes_df['Quote_Code_mapped']:\n",
    "    headers = {\n",
    "        'Accept': '*/*',\n",
    "        'Accept-Language': 'en-US,en;q=0.5',\n",
    "        'Connection': 'keep-alive',\n",
    "        'Origin': 'https://irbe7.com',\n",
    "        'Referer': 'https://irbe7.com/',\n",
    "        'Sec-Fetch-Dest': 'empty',\n",
    "        'Sec-Fetch-Mode': 'cors',\n",
    "        'Sec-Fetch-Site': 'same-site',\n",
    "        'Sec-GPC': '1',\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/144.0.0.0 Safari/537.36',\n",
    "        'sec-ch-ua': '\"Not(A:Brand\";v=\"8\", \"Chromium\";v=\"144\", \"Brave\";v=\"144\"',\n",
    "        'sec-ch-ua-mobile': '?0',\n",
    "        'sec-ch-ua-platform': '\"Windows\"',\n",
    "    }\n",
    "\n",
    "    params = {\n",
    "        'symbol': f'{quote}',\n",
    "        'resolution': '1D',\n",
    "        'from': f'{from_ts}',\n",
    "        'to': f'{to_ts}',\n",
    "        'countback': '365',\n",
    "    }\n",
    "\n",
    "    response = requests.get('https://data.irbe7.com/api/data/history', params=params, headers=headers)\n",
    "\n",
    "    data = response.json()\n",
    "        \n",
    "    # Check if data is valid\n",
    "    if not data or data.get('s') != 'ok' or not data.get('t'):\n",
    "        print(f\"❌ No quote data found for {quote}\")\n",
    "        continue\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'Date': pd.to_datetime(data['t'], unit='s'),\n",
    "        'Open': data['o'],\n",
    "        'High': data['h'],\n",
    "        'Low': data['l'],\n",
    "        'Close': data['c'],\n",
    "        'Volume': data['v']\n",
    "    })\n",
    "    \n",
    "    df['Quote_Code'] = latest_quotes_df.loc[latest_quotes_df['Quote_Code_mapped'] == quote, 'Quote_Code'].values[0] \n",
    "    prices = pd.concat([prices, df], ignore_index=True)\n",
    "    \n",
    "    print(f\"✅ {quote}: {len(df)} rows, from {df['Date'].min().date()} to {df['Date'].max().date()}\")\n",
    "    time.sleep(0.3)\n",
    "\n",
    "# load existing prices if exists\n",
    "try:\n",
    "    existing_prices = pd.read_csv('prices.csv')\n",
    "    prices = pd.concat([existing_prices, prices], ignore_index=True)\n",
    "    prices.drop_duplicates(subset=['Quote_Code', 'Date'], keep='last', inplace=True)\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "# save to prices.csv\n",
    "prices.to_csv('prices.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
